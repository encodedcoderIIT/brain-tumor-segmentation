{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "567cfaa4-4b5c-4534-a25c-a0f183fc82e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b351673-f34b-46fd-aaa6-b725104d8202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dice loss as defined above for 4 classes\n",
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    class_num = 4\n",
    "    for i in range(class_num):\n",
    "        y_true_f = K.flatten(y_true[:,:,:,i])\n",
    "        y_pred_f = K.flatten(y_pred[:,:,:,i])\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "   #     K.print_tensor(loss, message='loss value for class {} : '.format(SEGMENT_CLASSES[i]))\n",
    "        if i == 0:\n",
    "            total_loss = loss\n",
    "        else:\n",
    "            total_loss = total_loss + loss\n",
    "            \n",
    "    total_loss = total_loss / class_num\n",
    "#    K.print_tensor(total_loss, message=' total dice coef: ')\n",
    "    return total_loss\n",
    "\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n",
    "\n",
    "\n",
    "\n",
    "# Computing Precision \n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    \n",
    "# Computing Sensitivity      \n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "# Computing Specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fead2bac-9c5c-457c-842d-515b6d9c51d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"/home/amit/DSML_Brats/model_2024_2D_UNet.h5\", custom_objects= {'dice_coef': dice_coef, 'precision': precision, 'sensitivity':sensitivity, 'specificity': specificity, 'dice_coef_necrotic':dice_coef_necrotic,'dice_coef_edema':dice_coef_edema,'dice_coef_enhancing':dice_coef_enhancing })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe1025c-3894-4362-98b6-4b99647175bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/amit/DSML_Brats/Dataset/\"\n",
    "image_file = nib.load(os.path.join(data_path, \"BraTS-GLI-00006-101-t2f.nii.gz\"))\n",
    "image_file2 = nib.load(os.path.join(data_path, \"BraTS-GLI-00006-101-t1c.nii.gz\"))\n",
    "# label_file = nib.load(os.path.join(data_path, \"BraTS-GLI-00006-101-seg.nii.gz\"))\n",
    "\n",
    "image = image_file.get_fdata()  \n",
    "image2 = image_file2.get_fdata()  \n",
    "# label = label_file.get_fdata()  \n",
    "\n",
    "# Normalize image\n",
    "image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "image2 = (image2 - np.min(image2)) / (np.max(image2) - np.min(image2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "534efb1e-7578-40ee-98ce-4a13caf086bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the images\n",
    "slice_idx = image.shape[2] // 2  # Middle slice\n",
    "\n",
    "# Resize the images\n",
    "IMG_SIZE = 128\n",
    "flair_resized = cv2.resize(image[:, :, slice_idx], (IMG_SIZE, IMG_SIZE))\n",
    "ce_resized = cv2.resize(image2[:, :, slice_idx], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "# Stack them together to create the 2-channel input\n",
    "X_input = np.stack((flair_resized, ce_resized), axis=-1)  # Shape will be (IMG_SIZE, IMG_SIZE, 2)\n",
    "\n",
    "# Normalize the input\n",
    "X_input = X_input / np.max(X_input)  # Normalizing the input to [0, 1]\n",
    "\n",
    "# If you need to add an extra batch dimension\n",
    "X_input = np.expand_dims(X_input, axis=0)  # Shape will be (1, IMG_SIZE, IMG_SIZE, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b660abf8-bef9-401d-b878-1b3c789ef5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you also want to process the label\n",
    "label_resized = cv2.resize(label[:, :, slice_idx], (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "label_resized[label_resized >= 4] = 3  # Map to the last class\n",
    "label_one_hot = tf.one_hot(label_resized, 4)  # Convert to one-hot encoding (4 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c6a660e-b4d8-4954-82c7-48c79a385b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand dimensions for batch size (if necessary)\n",
    "label_one_hot = np.expand_dims(label_one_hot, axis=0)  # Shape will be (1, IMG_SIZE, IMG_SIZE, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8fd156a-80f6-4526-91ed-8b16d74e204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 17:39:21.017818: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-11-25 17:39:21.128291: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-11-25 17:39:21.421689: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 548.16MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-25 17:39:21.456456: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 548.16MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-25 17:39:21.613308: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 544.27MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-25 17:39:21.638914: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 544.27MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-25 17:39:21.744883: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 548.69MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-25 17:39:21.770762: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 548.69MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-25 17:39:21.856088: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 564.38MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-25 17:39:21.877848: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 564.38MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-25 17:39:21.906611: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 563.19MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-25 17:39:21.927285: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 563.19MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "prediction = model.predict(X_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22074f4e-ad7b-45e2-bbd7-8d84d842dc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, display the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the images\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the T2-FLAIR image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(flair_resized, cmap='gray')\n",
    "plt.title(\"T2-FLAIR Slice\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Plot the T1-contrast image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(ce_resized, cmap='gray')\n",
    "plt.title(\"T1-contrast Slice\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Plot the prediction (you can choose the channel with the max probability, for example)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(np.argmax(prediction[0], axis=-1), cmap='jet')  # Take the first batch and argmax over the classes\n",
    "plt.title(\"Model Prediction\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
